data:
  task_name: benign
  split: test_public # val, test_public, test_private
  train_fraction: 
  shuffle_seed: 0
  behavior_ids: []
  # sample_ids: "1-1,1-2,1-3,1-4,10-1,10-2,10-3,10-4" # list of example IDs to select specific samples
  testset_ids: "63-3,50-3,62-1,26-4,22-3,64-2,43-1,33-3,10-4,46-1,37-1,7-1,25-1,17-2,54-3,29-3,2-1,35-2,61-4,49-4,40-1,44-4,28-2,42-4,22-2,29-1,49-1,24-1,19-1,28-4,39-2,64-1,13-3,43-4,20-3,40-2,50-2,53-3,58-4,27-3,19-3,9-2,64-4,26-2,42-1,20-1,66-2,7-4,24-2,27-2,52-3,54-4,49-3,14-3,14-1,62-2,43-2,22-1,10-1,30-4,25-3,33-2,45-3,1-1,38-3,11-4,1-4,9-4,66-1,49-2,42-2,63-4,52-2,23-1,30-1,40-4,35-3,58-1,52-4,44-1,33-1,10-3,13-2,29-4,19-2,58-3,50-1,26-1,61-3,13-1,62-3,28-1,17-4,46-2,23-4,54-2,35-4,44-3,29-2,38-4,45-1,46-3,26-3,7-3,39-4,37-3" # list of IDs for testset; others used for trainset
  detailed_behaviors: 
  hint_included: 
  n_irrelevant_tools: 0

models:
  lm_name: openai/gpt-4o-mini # gpt-4o-mini, gpt-5-mini, gemini-2.5-flash, qwen3-8b 
  lm_temperature: 0 # 0 for others
  seed: 42
  max_tokens: 4096 # 4096 for others
  refusal_judge_model:  openai/gpt-4o # openai/gpt-4o-mini or openai/gpt-4o-2024-08-06
  semantic_judge_model: openai/gpt-4o # openai/gpt-4o-mini or openai/gpt-4o-2024-08-06
  # api_base: 
  api_base: https://api.openai.com/v1/

optimization:
  optim_seed: 6793115
  auto_mode: medium # light, medium, heavy
  num_threads: 4
  algorithm: gepa # one of: mipro, copro, gepa
  run_optimization: true
  optimize_refusal: false  # set true to optimize using refusal metric instead of task success

experiment:
  name: CausalEvolve_baseline
  uri: http://127.0.0.1:5001
